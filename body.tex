\section{Introduction}

Phylogenetics is rapidly progressing as the statistical foundation of
comparative biology, providing a framework for accounting for the shared
ancestry inherent in biological data.
Soon after phylogenetics became feasible as a likelihood-based statistical
endeavor \citep{Felsenstein1981}, models started becoming richer to better
capture processes of biological diversification and character change.
This trend in model complexity made Bayesian approaches appealing, because they
can render inference under rich models practical by leveraging prior
information and numerical techniques (e.g., data augmentation).

From the earliest days of Bayesian phylogenetics \citep{Rannala1996,Mau1997},
the numerical tool of choice for approximating the posterior distribution was
Markov chain Monte Carlo (MCMC).
By only considering the ratios of posterior densities, MCMC obviates the need
for calculating the proportionality constant in the denominator of Bayes' rule.
This proportionality constant is better known as the marginal likelihood---the
probability of the data under the model, averaged, with respect to the prior,
over the whole parameter space.
This marginalized measure of model fit cannot be solved analytically due to
the large number of parameters in phylogenetic models that need to be summed or
integrated.

Marginal likelihoods are central to model comparison in a Bayesian framework.
Thus, we cannot avoid calculating them if we want to be able to compare the fit
of phylogenetic models.
As the diversity and richness of phylogenetic models has increased, there has
been a renewed appreciation of the importance of such Bayesian model
comparison.
As a result, there has been a lot of work over the last decade to develop
methods for estimating marginal likelihoods of phylogenetic models.

The goals of this review are to
(1) provide a summary about what marginal likelihoods are and why they are
useful,
(2) review the various methods available for approximating marginal likelihoods
of phylogenetic models,
(3) review applications
(4) \ldots

\section{What is a marginal likelihood?}

\begin{linenomath}
A marginal likelihood likelihood is the average fit of a model to a dataset, where
the average is weighted by the prior.
\begin{equation}
    p(\parameters \given \data, \model) = \frac{
        p(\data \given \parameters, \model) p(\parameters \given \model)
    }{
        p(\data \given \model)
    }
    \label{eq:bayesRule}
\end{equation}
\begin{equation}
    p(\data \given \model[1]) = \int_{\parameters[1]}
    p( \data \given \parameters[1], \model[1]) p(\parameters[1] \given \model[1])
    \diff{\parameters[1]},
    \label{eq:marginalLikelihood}
\end{equation}
and
\begin{equation}
    p(\data \given \model[2]) = \int_{\parameters[2]}
    p( \data \given \parameters[2], \model[2]) p(\parameters[2] \given \model[2])
    \diff{\parameters[2]},
\end{equation}
The posterior probability of \model[1] is then
\begin{equation}
    p(\model[1] \given \data) = \frac{
        p(\data \given \model[1]) p(\model[1])
    }{
        p(\data \given \model[1]) p(\model[1]) + p(\data \given \model[2]) p(\model[2])
    }.
\end{equation}
\begin{equation}
    \frac{p(\model[1] \given \data)}{p(\model[2] \given \data)} = 
    \frac{p(\data \given \model[1])}{p(\data \given \model[2])}
    \frac{p(\model[1])}{p(\model[2])}
\end{equation}
\end{linenomath}

Layout what a marginal likelihood is; the marginal probability of the data
under the model. Start with Bayes' rule; marginal likelihood is the normalizing
constant. It is ``averaging'' (integrating) the likelihood with respect to the
prior.

Make sure to tie in phylogenetics specifically.

\section{Why are marginal likelihoods useful}

Describe how it is used for model choice. Might help to introduce maximum
likelihood model choice among nested models and the problem of penalizing
paremeters. Averaging over the model provides a ``natural'' penalty for
parameters.

The ratio of marginal likelihoods tells us the factor by which the data updated
the prior odds ratio; the Bayes factor!


\section{How to approximate a marginal likelihood}

Perhaps the simplest numerical approximation of the marginal likelihood is to
draw samples of a model's parameters from their respective prior distributions.
This turns the intractable integral into a sum of the samples' likelihoods.
Because the prior weight of each sample is one in this case, the marginal
likelihood can be approximated by simply calculating the average likelihood of
the prior samples.
Similarly, if we have a sample of the parameters from the posterior
distribution---like one obtained from a ``standard'' Bayesian phylogenetic
analysis via MCMC---we can again use summation to approximate the integral.
The weight of each sample is the ratio of the prior density to the posterior
density.
As a result, the sum simplifies to the harmonic mean (HM) of the likelihoods
from the posterior sample \citep{Newton1994}.
Both of these techniques are importance-sampling approximations, and suffer
from the fact that the prior and posterior are often \emph{very} divergent,
with the latter usually \emph{much} more peaked than the former.
A finite sample from the prior will often yield an underestimate of the
marginal likelihood, because the region of parameter space with high likelihood
is likely to be missed.
Whereas a finite sample from the posterior will almost always lead to an
overestimate, because it will contain very few samples outside of the region of
high likelihood, where the prior has a strong downward ``pull'' on the average
likelihood.

Recent methods developed to estimate marginal likelihoods generally fall into
two categories of how to deal with the sharp contrast between the prior
and posterior that cripples the simple importance-sampling approaches
mentioned above.
One general strategy is to turn the giant leap between the unnormalized
posterior and prior into many small steps along a series of power posterior
distributions.
The second strategy is to turn the giant leap between the posterior and prior
into a smaller leap between the posterior and a reference distribution that is
as similar as possible to the posterior.
These approaches are not mutually exclusive (e.g., see Fan et al.\
\citeyear{Fan2011}), but they serve as a useful way to categorize marginal
likelihood approximation methods.
In practical terms, the first strategy is computationally expensive, because
samples need to be collected from each of the power posterior distributions,
which is not part of a ``standard'' Bayesian phylogenetic analysis.
The second strategy is very inexpensive because it attempts to approximate the
marginal likelihood using only the posterior samples collected from a
``standard'' analysis.

\subsection{Approaches that use only posterior samples}

\begin{itemize}
    \item Generalized harmonic mean (GHM) \citep{Gelfand1994}
    \item Inflated density ratio \citep{Arima2012}
    \item Partition weighted kernel (PWK) \cite{Wang2017}; Looks promising, but
        not used for phylo yet.
        \begin{itemize}
            \item Entails partitioning parameter space into regions within which the
                posterior density is relatively homogeneous.
            \item Given the complex structure of phylogenetic models
                (continuous and discrete elements; cite hyper-dimensional
                orange), it's not clear how this would be done.
        \end{itemize}
\end{itemize}

\subsection{Approaches that use power posterior samples}

\begin{itemize}
    \item Path-sampling \citep{Lartillot2006}
    \item Stepping-stone \citep{Xie2011}
    \item Generalized stepping stone \citep{Fan2011}
\end{itemize}

\subsection{Importance sampling-ish}

\begin{itemize}
    \item Sequential stochastic approximation Monte Carlo (SSAMC)
        \citep{Liang2007,Cheon2008}
    \item Sequential Monte Carlo (SMC) \citep{Jordan2012}
    \item Direct sampling (model averaging)
    \item Approximate-likelihood Bayesian approaches. Wegmann's ABCToolbox
        approximates the posterior distribution with a GLM, and then takes the
        marginal of that distribution. Knowles' lab is using this to compare
        different phylogeographic models. It would be interesting to know how
        accurate these marginal likelihoods are (my guess is that they are are
        not so good). As far as I'm aware there have been no analyses to assess
        this.
        \thought{Could perform Christian Robert-esque assessment of the
            accuracy and precision of GLM approximations of the marginal
            probability of the data.}
\end{itemize}

\subsection{Approximate-likelihood approaches}

\begin{itemize}
    \item Approximate-likelihood Bayesian approaches. Wegmann's ABCToolbox
        approximates the posterior distribution with a GLM, and then takes the
        marginal of that distribution. Knowles' lab is using this to compare
        different phylogeographic models. It would be interesting to know how
        accurate these marginal likelihoods are (my guess is that they are are
        not so good). As far as I'm aware there have been no analyses to assess
        this.
\end{itemize}

\section{Uses of marginal likelihoods}

\subsection{Species delimitation}

Bayes factor delimitation in *BEAST and SNAPP.

\subsection{Comparing partitioning schemes}

Brandley and others used importance sampling (harmonic mean estimator) to
compare the fit of different ways to partition sequence alignments into rate
categories.

\subsection{Comparing nucleotide substitution models}

\subsection{Comparing ``relaxed clock'' models}

\subsection{Comparing tree models (priors)}

\subsection{Comparing phylogeographic models}

Knowles' lab is using Weggman's GLM approximation to compare the fit of
phylogeographic models built atop different ecological nich models.

Search for other uses of the GLM marginal.
